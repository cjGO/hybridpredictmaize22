{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40710d3-ed98-4dea-89f3-5c68a6ad6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from hybridpredictmaize22.GEMdataset import *\n",
    "from hybridpredictmaize22.GEMlearn import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e12663-7f04-4833-967e-94de48ea2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11cb91c-d343-4c94-9cdb-39416e705f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136012 plots with 26 features\n",
      "77431 daily weather measurements with 18 features\n",
      "4928 hybrids\n"
     ]
    }
   ],
   "source": [
    "trait_csv='./data/Training_Data/1_Training_Trait_Data_2014_2021.csv'\n",
    "weather_csv = './data/Training_Data/4_Training_Weather_Data_2014_2021.csv'\n",
    "snp_folder = './data/snpCompress/PCS_10/'\n",
    "\n",
    "\n",
    "phenotype = pd.read_csv(trait_csv)\n",
    "weather = pd.read_csv(weather_csv)\n",
    "genotype = collect_snps(Path(snp_folder))\n",
    "\n",
    "print(f'{phenotype.shape[0]} plots with {phenotype.shape[1]} features')\n",
    "print(f'{weather.shape[0]} daily weather measurements with {weather.shape[1]} features')\n",
    "print(f'{genotype[0].shape[0]} hybrids')\n",
    "\n",
    "#clip days per year\n",
    "weather = clip_weatherdays(weather)\n",
    "#add year column\n",
    "weather['Year'] = [x.split('_')[1] for x in weather['Env']] #Store Year in a new column\n",
    "\n",
    "#removes yield data where no weather data\n",
    "setYield = set(phenotype['Env'])\n",
    "setWeather = set(weather['Env'])\n",
    "only_yield = setYield - setWeather\n",
    "only_weather = setWeather - setYield\n",
    "phenotype = phenotype.iloc[[x not in only_yield for x in phenotype['Env']],:]\n",
    "#removes yield data where no genotype data\n",
    "setSNP = set(genotype[0])\n",
    "setYield = set(phenotype['Hybrid'])\n",
    "only_yield = setYield - setSNP\n",
    "phenotype = phenotype.iloc[[x not in only_yield for x in phenotype['Hybrid']],:]\n",
    "\n",
    "#remove rows w/o yields\n",
    "phenotype = phenotype.loc[np.isnan(phenotype['Yield_Mg_ha'])==False,:]\n",
    "\n",
    "Weather = weather.reset_index()\n",
    "Yield = phenotype.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016b181-5558-4324-9ecc-8c36454296cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a GEM dataset\n",
    "testYear = 2019\n",
    "\n",
    "gem = GemDataset(\n",
    "W=WT(Weather,testYear=testYear),\n",
    "Y=ST(Yield,testYear=testYear),\n",
    "G=Genotype,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d8575-4d4c-4016-ba26-0c5819956203",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = GemDataset(gem.W.Tr, gem.Y.Tr, gem.SNP)\n",
    "te_ds = GemDataset(gem.W.Te, gem.Y.Te, gem.SNP)\n",
    "tr_dl = DataLoader(tr_ds, batch_size=4)\n",
    "te_dl = DataLoader(te_ds, batch_size=4)\n",
    "dls = DataLoaders(tr_dl,te_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3d223-dba2-4e00-9aec-0fb3b344c77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5186, 21277, 22973,  9464,  9434, 17978,     0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.isnan(gem.Y.Tr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df3b8c-eb9d-4052-a3cd-921e9b4b0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2])\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Create a model with input_size = 784, hidden_size = 256, and num_classes = 2 (binary classification)\n",
    "model = MLP(input_size=784, hidden_size=256, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa51e46-fc48-4a92-8f98-9f0c23a0dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/burbank/miniconda3/envs/fastai/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.g_model = MLP(100,50,25)\n",
    "        self.w_model = MLP(4800,50,25)\n",
    "        self.hidden = nn.LazyLinear(50)\n",
    "        self.out = nn.LazyLinear(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        g, w = x\n",
    "        w = w.view(w.shape[0], w.shape[1], w.shape[2])\n",
    "        g = self.g_model(g)\n",
    "        w = self.w_model(w)\n",
    "        x = torch.concat((g,w),axis=1)\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "e = Ensemble()\n",
    "#e((learn.batch[1].type(torch.float32),learn.batch[2].type(torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1a5ca-618a-4885-bcdf-86a0b5f623ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmlp = MLP(4800, 100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f776a3d8-3c62-4c84-b219-d15717ff69dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0896],\n",
       "        [-0.1707],\n",
       "        [-0.1355],\n",
       "        [-0.0956]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmlp(w.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6e36a-f99e-44ec-81b3-13ffbeaa6a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310daca3-4032-4277-a0dc-b12d2ea8b0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a026b-6c79-4f8d-94c5-87bcc2a43c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import fastcore.all as fc\n",
    "from functools import partial\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, dls=(0,), loss_func=F.mse_loss, lr=0.1, cbs=None, opt_func=optim.SGD):\n",
    "        cbs = fc.L(cbs)\n",
    "        self.cb_ctx = partial(callback_ctx, self.callback)\n",
    "        fc.store_attr()\n",
    "\n",
    "    def one_epoch(self, train):\n",
    "        self.model.train(train)\n",
    "        self.dl = self.dls.train if train else self.dls.valid\n",
    "        with self.cb_ctx('epoch'):\n",
    "            for self.iter,self.batch in enumerate(self.dl):\n",
    "                with self.cb_ctx('batch'):\n",
    "                    self.predict()\n",
    "                    self.get_loss()\n",
    "                    if self.training:\n",
    "                        self.backward()\n",
    "                        self.step()\n",
    "                        self.zero_grad()\n",
    "    \n",
    "    def fit(self, n_epochs=1, train=True, valid=True, cbs=None, lr=None):\n",
    "        cbs = fc.L(cbs)\n",
    "        # `add_cb` and `rm_cb` were added in lesson 18\n",
    "        for cb in cbs: self.cbs.append(cb)\n",
    "        try:\n",
    "            self.n_epochs = n_epochs\n",
    "            self.epochs = range(n_epochs)\n",
    "            self.opt = self.opt_func(self.model.parameters(), self.lr if lr is None else lr)\n",
    "            with self.cb_ctx('fit'):\n",
    "                for self.epoch in self.epochs:\n",
    "                    if train: self.one_epoch(True)\n",
    "                    if valid: torch.no_grad()(self.one_epoch)(False)\n",
    "        finally:\n",
    "            for cb in cbs: self.cbs.remove(cb)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in ('predict','get_loss','backward','step','zero_grad'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)\n",
    "    \n",
    "    @property\n",
    "    def training(self): return self.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5a857-9e16-4b3d-ade8-f4656a9fd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SingleBatchCB(Callback):\n",
    "    def __init__(self,batches):\n",
    "        self.batches = batches\n",
    "        order = 1\n",
    "    def before_fit(self,learn): self.count = 0\n",
    "    def after_batch(self, learn):\n",
    "        self.count += 1\n",
    "        #print(learn.loss)\n",
    "        if self.count > self.batches:\n",
    "            print(f'{self.count} batches')\n",
    "            raise CancelFitException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8f919-0d18-4fc7-a05a-bd55ced7ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device=def_device): fc.store_attr()\n",
    "    def before_fit(self, learn): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74e871-c744-4512-bedd-8acf874010a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2642/593469583.py:7: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  learn.loss = learn.loss_func(learn.preds,learn.batch[0][:,-1].type(torch.float32))\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "class TrainCB(Callback):\n",
    "    def predict(self, learn):\n",
    "        learn.preds = learn.model([learn.batch[1].type(torch.float32),learn.batch[2].type(torch.float32)])\n",
    "    def get_loss(self, learn):\n",
    "        #print(learn.preds.squeeze().shape,learn.batch[0][:,-1].type(torch.float32).shape)\n",
    "        learn.loss = learn.loss_func(learn.preds,learn.batch[0][:,-1].type(torch.float32))\n",
    "    def backward(self, learn): learn.loss.backward()\n",
    "    def step(self, learn): learn.opt.step()\n",
    "    def zero_grad(self, learn): learn.opt.zero_grad()\n",
    "\n",
    "cbs = [TrainCB()]\n",
    "model = Ensemble()\n",
    "learn = Learner(model,dls, cbs=cbs, lr=.0001)\n",
    "learn.fit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
