{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEMlearner\n",
    "\n",
    "> This package will hold the GxExM dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/burbank/miniconda3/envs/fastai/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "#| hide\n",
    "from hybridpredictmaize22.GEMdataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leapdays(weather_data):\n",
    "    obs = {}\n",
    "    for env in weather_data['Env']:\n",
    "        if env not in obs.keys():\n",
    "            obs[env] = 1\n",
    "        else:\n",
    "            obs[env] += 1\n",
    "            \n",
    "    days = []\n",
    "    for i in obs.values():\n",
    "        for x in np.arange(1,i+1):\n",
    "            days.append(x)\n",
    "    weather_data['day'] = days\n",
    "    \n",
    "    return weather_data.drop(weather_data[weather_data['day'] == 366].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_snps = Path('data/snpCompress/')\n",
    "data_path = Path('data/')\n",
    "\n",
    "path_train_weatherTable =data_path/'Training_Data/4_Training_Weather_Data_2014_2021.csv'\n",
    "path_train_yieldTable = data_path/'Training_Data/1_Training_Trait_Data_2014_2021.csv'\n",
    "\n",
    "snp_data = collect_snps(path_snps/'EVEN_10') # Read in the SNP profiles\n",
    "yield_data = pd.read_csv(path_train_yieldTable) # Read in trait data \n",
    "yield_data = yield_data[yield_data['Twt_kg_m3'].notnull()] #Remove plots w/ missing yields\n",
    "weather_data = pd.read_csv(path_train_weatherTable) # Read in Weather Data\n",
    "weather_data['Year'] = [x.split('_')[1] for x in weather_data['Env']] #Store Year in a new column\n",
    "#removes yield data where no weather data\n",
    "setYield = set(yield_data['Env'])\n",
    "setWeather = set(weather_data['Env'])\n",
    "only_yield = setYield - setWeather\n",
    "only_weather = setWeather - setYield\n",
    "yield_data = yield_data.iloc[[x not in only_yield for x in yield_data['Env']],:]\n",
    "#removes yield data where no genotype data\n",
    "setSNP = set(snp_data[0])\n",
    "setYield = set(yield_data['Hybrid'])\n",
    "only_yield = setYield - setSNP\n",
    "yield_data = yield_data.iloc[[x not in only_yield for x in yield_data['Hybrid']],:]\n",
    "\n",
    "weather_data = remove_leapdays(weather_data)\n",
    "\n",
    "#Create a GEM dataset\n",
    "test_split = 2019\n",
    "gem = GEM(test_split)\n",
    "gem.Y = YT(yield_data, test_split)\n",
    "gem.W = WT(weather_data, test_split)\n",
    "gem.SNP = collect_snps(path_snps/'PCS_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = GemDataset(gem.W.Tr, gem.Y.Tr, gem.SNP)\n",
    "te_ds = GemDataset(gem.W.Te, gem.Y.Te, gem.SNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(gem.W.Tr.select_dtypes('float'))\n",
    "\n",
    "xt = pca.transform(gem.W.Tr.select_dtypes('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gem.SNP[1][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y,g,w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtr_dataloader\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "y,g,w = next(iter(tr_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        for l in self.layers:x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gwModel(nn.Module):\n",
    "    def __init__(self, gi,gh,wi,wh,c):\n",
    "        super().__init__()\n",
    "        self.gi = nn.Linear(gi,gh)\n",
    "        self.wi = nn.Linear(wi,wh)\n",
    "\n",
    "        self.gh = nn.Linear(gh,c)\n",
    "        self.wh = nn.Linear(wh,c)\n",
    "    \n",
    "        self.o = nn.Linear(c*2,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        g,w = x\n",
    "        \n",
    "        w=w.flatten()\n",
    "        \n",
    "        #snp\n",
    "        g = self.gi(g)\n",
    "        g = torch.relu(g)\n",
    "        g = self.gh(g)\n",
    "        g = torch.relu(g)\n",
    "        \n",
    "        #wet\n",
    "        w = self.wi(w)\n",
    "        w = torch.relu(w)\n",
    "        w = self.wh(w)\n",
    "        w = torch.relu(w)\n",
    "        \n",
    "        #print(w.shape)\n",
    "        g = (g.flatten())\n",
    "        x = torch.cat((w,g), dim = 0)\n",
    "        out = self.o(x)\n",
    "        return out\n",
    "        \n",
    "       # print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = g.flatten().shape[0]\n",
    "wi = w.flatten().shape[0]\n",
    "\n",
    "gw = gwModel(gi,10,wi,10,5)\n",
    "\n",
    "g=g.type(torch.float32)\n",
    "w=w.type(torch.float32)\n",
    "gw([g,w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = gwModel(gi,10,wi,10,5)\n",
    "opt = Optimizer(gw.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(10):\n",
    "    for batch in tqdm(range(1000)):\n",
    "        y,g,w = next(iter(tr_dataloader))\n",
    "        g=g.type(torch.float32)\n",
    "        w=w.type(torch.float32)\n",
    "        predict = gw([g,w])\n",
    "        loss = loss_func(y.type(torch.float32),predict.squeeze().type(torch.float32))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newis = []\n",
    "for i in [x.detach().numpy() for x in losses]:\n",
    "    if i > 0.1:\n",
    "        pass\n",
    "    else:\n",
    "        newis.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot([x.detach().numpy() for x in losses],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_size1, input_size2, hidden_size, output_size):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(input_size1 + input_size2, hidden_size)\n",
    "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, x1, x2):\n",
    "    # Concatenate the inputs\n",
    "    x = torch.cat((x1, x2), dim=1)\n",
    "    # Pass the concatenated inputs through the model\n",
    "    x = self.fc1(x)\n",
    "    x = torch.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MLP(input_size1=10, input_size2=5, hidden_size=20, output_size=1)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "  # Generate some fake data for training\n",
    "  input1 = torch.randn(64, 10)\n",
    "  input2 = torch.randn(64, 5)\n",
    "  target = torch.randn(64, 1)\n",
    "\n",
    "  # Forward pass\n",
    "  output = model(input1, input2)\n",
    "  loss = criterion(output, target)\n",
    "\n",
    "  # Backward pass and optimization\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wModel = Model(len(w[0].flatten()), 100, 1)\n",
    "opt = Optimizer(wModel.parameters())\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 1\n",
    "\n",
    "tr_dataloader = DataLoader(tr_ds, batch_size=bs, shuffle=True)\n",
    "te_dataloader = DataLoader(te_ds, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,g,w = next(iter(tr_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,g,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wModel = Model(len(w[0].flatten()), 2, 1)\n",
    "opt = Optimizer(wModel.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "losses = []\n",
    "for _ in range(1000):\n",
    "    y,g,w = next(iter(tr_dataloader))\n",
    "    xb = w.flatten().type(torch.float32)\n",
    "    preds = wModel(xb)\n",
    "    loss = loss_func(preds, y.type(torch.float32))\n",
    "    losses.append(loss.detach().numpy())\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for l in wModel.layers:\n",
    "            if hasattr(l, 'weight'):\n",
    "                l.weight -= l.weight.grad * lr\n",
    "                l.bias   -= l.bias.grad   * lr\n",
    "                l.weight.grad.zero_()\n",
    "                l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    yield from losses\n",
    "    \n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(islice(x,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wModel = Model(len(w[0].flatten()), 2, 1)\n",
    "opt = Optimizer(wModel.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(5):\n",
    "    for batch in tqdm(range(100)):\n",
    "        y,g,w = next(iter(tr_dataloader))\n",
    "        weather_input = w.reshape(bs,w.shape[1]*w.shape[2]).type(torch.float32)\n",
    "        predict = wModel(weather_input)\n",
    "        loss = loss_func(y.type(torch.float32),predict.squeeze().type(torch.float32))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        losses.append(loss)\n",
    "\n",
    "plt.plot([x.detach().numpy() for x in losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gModel = Model(len(g[0].flatten()), 50, 1)\n",
    "opt = Optimizer(gModel.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(5):\n",
    "    for batch in tqdm(range(100)):\n",
    "        y,g,w = next(iter(tr_dataloader))\n",
    "        g_input = g.reshape(bs,g.shape[1]).type(torch.float32)\n",
    "        predict = wModel(weather_input)\n",
    "        loss = loss_func(y.type(torch.float32),predict.squeeze().type(torch.float32))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        losses.append(loss)\n",
    "\n",
    "plt.plot([x.detach().numpy() for x in losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,g,w = next(iter(tr_dataloader))\n",
    "weather_input = w.reshape(bs,w.shape[1]*w.shape[2]).type(torch.float32)\n",
    "predict = wModel(weather_input)\n",
    "loss = loss_func(y.type(torch.float32),predict.type(torch.float32))\n",
    "loss.backward()\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wModel = Model(len(w[0].flatten()), 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_input = w.reshape(2,w.shape[1]*w.shape[2]).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = wModel(weather_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, inp in next(iter(tr_dataloader)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
