{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models\n",
    "\n",
    "> This package will hold the GxExM learner for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp GEMlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "from warnings import warn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torcheval.metrics import MeanSquaredError,Mean, R2Score\n",
    "from fastprogress import progress_bar,master_bar\n",
    "\n",
    "from hybridpredictmaize22.GEMdataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Create a list of linear layers, with the correct input and output dimensions\n",
    "        self.layers = torch.nn.ModuleList([torch.nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim) for i in range(num_layers - 1)])\n",
    "        self.layers.append(torch.nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        # Initialize the weights and biases of the linear layers using the Xavier initialization method\n",
    "        for layer in self.layers:\n",
    "            torch.nn.init.xavier_uniform_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                torch.nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the dropout layer to the input\n",
    "        x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Iterate through the linear layers, applying each one to the input\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
