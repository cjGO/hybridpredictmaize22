hybridpredictmaize22
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

Repo for analysis of GEM prediction for maize yield

## Install

``` sh
pip install hybridpredictmaize22
```

## How to use

A demo of the library specifically for this dataset

Generate random data that is the same form as the actual dataset

``` python
import random
#generate random SNP matrix
gene_dosages = [0, .5, 1]
years = [2018,2019]
snp_length = 100
number_hybrids = 20


number_environments = 10
env_col = []
for i,y in zip(np.arange(number_environments),[random.choice(years) for _ in range(number_environments)]):
    env_col.append(f'{i}_{y}')

snp_matrix = (np.arange(number_hybrids),np.array([[random.choice(gene_dosages) for x in range(snp_length)] for _ in range(number_hybrids)]))

#generate random yield data
random_yields = [random.uniform(-1,1) for _ in range(100)]
random_hybrids = [random.choice(range(number_hybrids)) for _ in range(100)]
random_environments = [random.choice((env_col)) for _ in range(100)]
```

``` python
yield_data = pd.DataFrame({"Hybrid":random_hybrids, "Yield_Mg_ha":random_yields, 'Env':random_environments})
yield_data.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hybrid</th>
      <th>Yield_Mg_ha</th>
      <th>Env</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>13</td>
      <td>0.350190</td>
      <td>6_2019</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6</td>
      <td>0.064413</td>
      <td>9_2018</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14</td>
      <td>0.467534</td>
      <td>2_2019</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
      <td>0.963206</td>
      <td>2_2019</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>-0.197542</td>
      <td>0_2019</td>
    </tr>
  </tbody>
</table>
</div>

``` python
Weather_Table = np.random.random((50,number_environments))
weather_table = {}
for c,i in enumerate(Weather_Table):
    weather_table[c] = i
    
weather_data = pd.DataFrame(weather_table)
weather_data.insert(0,'Env',env_col)
weather_data.insert(1,'Year',[x.split('_')[1] for x in env_col])

print(weather_data)
```

          Env  Year         0         1         2         3         4         5  \
    0  0_2019  2019  0.459257  0.737527  0.325568  0.339069  0.319371  0.770840   
    1  1_2018  2018  0.709798  0.069978  0.680074  0.400793  0.909106  0.979593   
    2  2_2019  2019  0.768011  0.607092  0.777468  0.181033  0.850854  0.803229   
    3  3_2018  2018  0.074027  0.409835  0.562800  0.458453  0.520226  0.047150   
    4  4_2018  2018  0.878995  0.092641  0.165952  0.608296  0.244000  0.988127   
    5  5_2019  2019  0.631363  0.251449  0.969365  0.004020  0.911174  0.923343   
    6  6_2019  2019  0.982455  0.177676  0.989299  0.067947  0.768552  0.643219   
    7  7_2018  2018  0.331000  0.065025  0.098610  0.933539  0.332291  0.726276   
    8  8_2019  2019  0.797633  0.532959  0.616582  0.775982  0.705979  0.317449   
    9  9_2018  2018  0.479941  0.077079  0.539941  0.587070  0.406727  0.216224   

              6         7  ...        40        41        42        43        44  \
    0  0.145404  0.989743  ...  0.810642  0.210158  0.696451  0.073473  0.275845   
    1  0.342592  0.636118  ...  0.662829  0.440427  0.307600  0.444437  0.117043   
    2  0.720562  0.199258  ...  0.671531  0.264091  0.359619  0.901644  0.077720   
    3  0.917968  0.132357  ...  0.073660  0.996262  0.550439  0.533343  0.526822   
    4  0.983519  0.072611  ...  0.866339  0.956450  0.640198  0.227137  0.795131   
    5  0.031763  0.347501  ...  0.086512  0.117868  0.902342  0.975155  0.510526   
    6  0.425223  0.928544  ...  0.307677  0.492413  0.987043  0.019421  0.210176   
    7  0.573278  0.334071  ...  0.224309  0.915200  0.660499  0.013849  0.972140   
    8  0.927877  0.052121  ...  0.643346  0.457522  0.584144  0.471953  0.761972   
    9  0.849030  0.349563  ...  0.296059  0.177592  0.940721  0.121564  0.711965   

             45        46        47        48        49  
    0  0.211234  0.150815  0.173858  0.893865  0.256201  
    1  0.967029  0.668639  0.180897  0.855687  0.808490  
    2  0.789628  0.916973  0.129690  0.981918  0.759025  
    3  0.262601  0.893604  0.317646  0.057753  0.620318  
    4  0.198063  0.765528  0.340870  0.437149  0.473265  
    5  0.043635  0.072521  0.480727  0.454561  0.954314  
    6  0.821824  0.234681  0.566459  0.497437  0.476021  
    7  0.923541  0.917899  0.625954  0.682846  0.359233  
    8  0.777865  0.278951  0.422312  0.035678  0.325676  
    9  0.040809  0.992331  0.382401  0.877628  0.466656  

    [10 rows x 52 columns]

``` python
yield_data
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hybrid</th>
      <th>Yield_Mg_ha</th>
      <th>Env</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>13</td>
      <td>0.350190</td>
      <td>6_2019</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6</td>
      <td>0.064413</td>
      <td>9_2018</td>
    </tr>
    <tr>
      <th>2</th>
      <td>14</td>
      <td>0.467534</td>
      <td>2_2019</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
      <td>0.963206</td>
      <td>2_2019</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>-0.197542</td>
      <td>0_2019</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>18</td>
      <td>-0.191020</td>
      <td>1_2018</td>
    </tr>
    <tr>
      <th>96</th>
      <td>10</td>
      <td>-0.926472</td>
      <td>2_2019</td>
    </tr>
    <tr>
      <th>97</th>
      <td>3</td>
      <td>-0.454691</td>
      <td>5_2019</td>
    </tr>
    <tr>
      <th>98</th>
      <td>10</td>
      <td>0.408324</td>
      <td>6_2019</td>
    </tr>
    <tr>
      <th>99</th>
      <td>14</td>
      <td>0.719746</td>
      <td>1_2018</td>
    </tr>
  </tbody>
</table>
<p>100 rows Ã— 3 columns</p>
</div>

``` python
#Create a GEM dataset
test_split = 2019
gem = GEM(test_split)
gem.Y = YT(yield_data, test_split)
gem.W = WT(weather_data, test_split)
gem.SNP = snp_matrix
```

``` python
#example of how to unscale a value
gem.Y.scaler.inverse_transform(np.array(1.4).reshape(-1,1))
```

    array([[0.75302418]])

``` python
gem.Y.plot_yields()
```

![](index_files/figure-commonmark/cell-9-output-1.png)

``` python
ds = GemDataset(gem.W.Tr, gem.Y.Tr, gem.SNP)
next(iter(ds))
```

    (tensor(0.1281),
     tensor([1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,
             0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 1.0000, 1.0000, 1.0000, 0.5000,
             1.0000, 0.5000]),
     tensor([[ 0.6586, -1.3527,  0.2799,  1.6154, -1.0831, -1.2287,  0.7447,  1.0475,
              -1.7051, -0.6592, -1.6990,  0.8659,  0.1971, -1.5005,  1.4679, -0.0057,
              -1.3124,  0.9911,  0.0959,  1.6687,  0.6416,  1.3909, -0.1510,  1.0113,
               1.3073, -1.7838,  1.4986, -0.6473,  0.9429, -0.3509, -1.2243, -0.0549,
               1.1983, -0.7537, -0.5440,  0.9003,  0.5778, -1.1093, -0.5868,  1.4705,
               1.7104,  0.6460, -1.9530,  0.3982, -0.6292, -0.8740,  1.7787, -0.7473,
              -1.0528, -0.6391]]))

``` python
tr_ds = GemDataset(gem.W.Tr, gem.Y.Tr, gem.SNP)
te_ds = GemDataset(gem.W.Te, gem.Y.Te, gem.SNP)
```

``` python
tr_dl = DataLoader(tr_ds, batch_size=4)
te_dl = DataLoader(te_ds, batch_size=4)
dls = DataLoaders(tr_dl,te_dl)
```

``` python
class MLP(torch.nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = torch.relu(x)
        x = self.fc2(x)
        return x
```

``` python
from torcheval.metrics import MeanSquaredError,Mean, R2Score
```

``` python
model = MLP(20,100, 1)
cbs = [TrainCB()]
learn = Learner(model, dls, F.mse_loss, lr=.25, cbs=cbs)
learn.fit(1)
```

    /mnt/c/Users/cltng/OneDrive/Documents/Projects/hybridpredictmaize22/hybridpredictmaize22/GEMlearn.py:268: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
      learn.loss = learn.loss_func(learn.preds.squeeze(), learn.batch[0])
